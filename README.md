## Big Data Definition
Big data is large enough not to handle or manipulate or too complex to process with the tools easily. 
For example, City's utility systems such as sewer, water, electricity, or structures are getting a lot of information daily and are hard to analyze.

## There are 6 V's of Big Data 

- **Volume:** A large amount of data generated cannot be stored or analyzed on a single machine. 
- **Velocity:** Speed of generating data in streams, online, offline, or real-time.
- **Variety:** Different kinds of formatted data generated by different sources
- **Variability:** Including inconsistency in data management.
- **Veracity:**  Quality and reliability of data is important as having a data 
- **Value:** Data has value if you can turn it into meaningful results. 


## Phases of Big Data Analysis

- 1. The first process is collecting valuable data from different sources. Then, apply the suitable filters to the generated data to obtain meaningful data. 

- 2. The Second process of handling big data is extraction and cleaning. Pulling required or requested data from the system's sources gives structured information to start your analysis. Cleaning is an initial part of the analysis and includes removing irrelevant data, deduplicates, fixing missing data, validating data, etc. 

- 3. The third phase is data integration, aggregation, and representation. The purpose of integration and aggregation is to collect and express raw data in a summary form for analysis from different data sources. The data can be presented in many ways with many visual tools. However, graphs and Charts are the most common tools for simply displaying the data to make it more readable to people. 

