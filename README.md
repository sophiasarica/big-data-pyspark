## Big Data Definition
Big data is large enough not to handle or manipulate or too complex to process with the tools easily. 
For example, City's utility systems such as sewer, water, electricity, or structures are getting a lot of information daily and are hard to analyze.

 DATA603-Fall2022-Lecture 2-Intro2BigData (1)



## There are 6 V's of Big Data 

- **Volume:** A large amount of data generated cannot be stored or analyzed on a single machine. 
- **Velocity:** Speed of generating data in streams, online, offline, or real-time.
- **Variety:** Different kinds of formatted data generated by different sources
- **Variability:** Including inconsistency in data management.
- **Veracity:**  Quality and reliability of data is important as having a data 
- **Value:** Data has value if you can turn it into meaningful results. 

 https://www.sydle.com/blog/big-data-definition-importance-and-types-614b791388e600016afa7fc3/


## Phases of Big Data Analysis

1. The first process is collecting valuable data from different sources. Then, apply the suitable filters to the generated data to obtain meaningful data. 

2. The Second process of handling big data is extraction and cleaning. Pulling required or requested data from the system's sources gives structured information to start your analysis. Cleaning is an initial part of the analysis and includes removing irrelevant data, deduplicates, fixing missing data, validating data, etc. 

3. The third phase is data integration, aggregation, and representation. The purpose of integration and aggregation is to collect and express raw data in a summary form for analysis from different data sources. The data can be presented in many ways with many visual tools. However, graphs and Charts are the most common tools for simply displaying the data to make it more readable to people. 

4. Query Processing is another analysis phase that retrieves data from databases using some commands. Data querying is not always providing complete analysis and data. The relationship between data tables helps organize data and create data models.

5. Making data-driven decisions is significant for business.Therefore analysis results should be carefully interpreted and used extra information if needed. 

  https://www.datapine.com/blog/data-interpretation-methods-benefits-problems/

  https://home.adelphi.edu/~siegfried/cs170/170l1.pdf

  https://www.ibm.com/docs/da/tnpm/1.4.2?topic=data-aggregation

  https://docs.holistics.io/docs/data-model


## Challenges in Big Data analysis

***Heterogeneity and Incompleteness*** 

Heterogeneity refers to a wide variety of data, which is not practical for computer systems. So, data needs to be well structured before starting any analysis. On the other hand, incompleteness points to missing data that is not easy to handle. Heterogeneity and incompleteness can have a significant effect on the data analysis results. 

***Scale***

Every day, data volume increases incredibly. Unfortunately, traditional computer storing systems cannot cope with data growth succefully. Therefore, we need more efficient and effective scaling of big data systems. 

***Timeliness***

Dealing with time is the most challenging part of analyzing data regarding a query or search problems. Even more difficult if the query or search is required in real-time from streaming data sources. In this kind of situations, the result of the analysis is required immediately. In this cases the results may not be complete and satisfactory. 


***Privacy***

The other problem we are facing with growing big data is privacy. Personal information can use or share inappropriately from multiple sources causing substantial privacy concerns. 

***Human Collaboration***

Today we still need human contributions to help computer systems analyze big data. Computers can not detect some errors, uncertainty, misleading, and conflicts as humans; hence human expertise and domain knowledge still play a critical role in today's computer systems. 

https://cra.org/ccc/wp-content/uploads/sites/2/2015/05/bigdatawhitepaper.pdf
